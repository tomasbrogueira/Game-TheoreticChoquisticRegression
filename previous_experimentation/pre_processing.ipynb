{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets Pre-Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Steps\n",
    "    - 8020 train-test split\n",
    "    - oversampling for covid dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Datasets\n",
    "Some are imported as pandas dataframes using kagglehub.\n",
    "\n",
    "Others are directly imported as x and y using ucimlrepo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banknote Authentication\n",
    "4 features \n",
    "\n",
    "1 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 267, 'name': 'Banknote Authentication', 'repository_url': 'https://archive.ics.uci.edu/dataset/267/banknote+authentication', 'data_url': 'https://archive.ics.uci.edu/static/public/267/data.csv', 'abstract': 'Data were extracted from images that were taken for the evaluation of an authentication procedure for banknotes.', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1372, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2012, 'last_updated': 'Fri Feb 16 2024', 'dataset_doi': '10.24432/C55P57', 'creators': ['Volker Lohweg'], 'intro_paper': None, 'additional_info': {'summary': 'Data were extracted from images that were taken from genuine and forged banknote-like specimens.  For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.  ', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '       1. variance of Wavelet Transformed image (continuous) \\r\\n       2. skewness of Wavelet Transformed image (continuous)\\r\\n       3. curtosis of Wavelet Transformed image (continuous)\\r\\n       4. entropy of image (continuous)\\r\\n       5. class (integer) \\r\\n', 'citation': None}}\n",
      "       name     role        type demographic  \\\n",
      "0  variance  Feature  Continuous        None   \n",
      "1  skewness  Feature  Continuous        None   \n",
      "2  curtosis  Feature  Continuous        None   \n",
      "3   entropy  Feature  Continuous        None   \n",
      "4     class   Target     Integer        None   \n",
      "\n",
      "                             description units missing_values  \n",
      "0  variance of Wavelet Transformed image  None             no  \n",
      "1  skewness of Wavelet Transformed image  None             no  \n",
      "2  curtosis of Wavelet Transformed image  None             no  \n",
      "3                       entropy of image  None             no  \n",
      "4                                   None  None             no  \n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "banknote_authentication = fetch_ucirepo(id=267) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = banknote_authentication.data.features \n",
    "y = banknote_authentication.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(banknote_authentication.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(banknote_authentication.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boold Transfusion\n",
    "4 features and one binary which will be the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:    Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
      "0                 2                 50                  12500             98   \n",
      "1                 0                 13                   3250             28   \n",
      "2                 1                 16                   4000             35   \n",
      "3                 2                 20                   5000             45   \n",
      "4                 1                 24                   6000             77   \n",
      "\n",
      "   whether he/she donated blood in March 2007  \n",
      "0                                           1  \n",
      "1                                           1  \n",
      "2                                           1  \n",
      "3                                           1  \n",
      "4                                           0  \n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the folder data \n",
    "file_path = \"transfusion.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"whenamancodes/blood-transfusion-dataset\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mammographic Mass\n",
    "5 features but used only 4 : BI-RADS is non-predictive so not used (first feature)\n",
    "\n",
    "1 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 161, 'name': 'Mammographic Mass', 'repository_url': 'https://archive.ics.uci.edu/dataset/161/mammographic+mass', 'data_url': 'https://archive.ics.uci.edu/static/public/161/data.csv', 'abstract': \"Discrimination of benign and malignant mammographic masses based on BI-RADS attributes and the patient's age.\", 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 961, 'num_features': 5, 'feature_types': ['Integer'], 'demographics': ['Age'], 'target_col': ['Severity'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2007, 'last_updated': 'Thu Mar 28 2024', 'dataset_doi': '10.24432/C53K6Z', 'creators': ['Matthias Elter'], 'intro_paper': {'ID': 448, 'type': 'NATIVE', 'title': 'The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process.', 'authors': 'M. Elter, R. Schulz-Wendtland, T. Wittenberg', 'venue': 'Medical Physics (Lancaster)', 'year': 2007, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/The-prediction-of-breast-cancer-biopsy-outcomes-two-Elter-Schulz-Wendtland/48666ddd437ca7bda95899d2ed1d0ae1ad58c9d0', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"Mammography is the most effective method for breast cancer screening\\r\\navailable today. However, the low positive predictive value of breast\\r\\nbiopsy resulting from mammogram interpretation leads to approximately\\r\\n70% unnecessary biopsies with benign outcomes. To reduce the high\\r\\nnumber of unnecessary breast biopsies, several computer-aided diagnosis\\r\\n(CAD) systems have been proposed in the last years.These systems\\r\\nhelp physicians in their decision to perform a breast biopsy on a suspicious\\r\\nlesion seen in a mammogram or to perform a short term follow-up\\r\\nexamination instead.\\r\\nThis data set can be used to predict the severity (benign or malignant)\\r\\nof a mammographic mass lesion from BI-RADS attributes and the patient's age.\\r\\nIt contains a BI-RADS assessment, the patient's age and three BI-RADS attributes\\r\\ntogether with the ground truth (the severity field) for 516 benign and\\r\\n445 malignant masses that have been identified on full field digital mammograms\\r\\ncollected at the Institute of Radiology of the\\r\\nUniversity Erlangen-Nuremberg between 2003 and 2006.\\r\\nEach instance has an associated BI-RADS assessment ranging from 1 (definitely benign)\\r\\nto 5 (highly suggestive of malignancy) assigned in a double-review process by\\r\\nphysicians. Assuming that all cases with BI-RADS assessments greater or equal\\r\\na given value (varying from 1 to 5), are malignant and the other cases benign,\\r\\nsensitivities and associated specificities can be calculated. These can be an\\r\\nindication of how well a CAD system performs compared to the radiologists.\\r\\n\\r\\nClass Distribution: benign: 516; malignant: 445\\r\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"6 Attributes in total (1 goal field, 1 non-predictive, 4 predictive attributes)\\r\\n\\r\\n1. BI-RADS assessment: 1 to 5 (ordinal, non-predictive!)  \\r\\n2. Age: patient's age in years (integer)\\r\\n3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\\r\\n4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\\r\\n5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\\r\\n6. Severity: benign=0 or malignant=1 (binominal, goal field!)\\r\\n\\r\\n\\r\\nMissing Attribute Values:\\r\\n    - BI-RADS assessment:    2\\r\\n    - Age:                   5\\r\\n    - Shape:                31\\r\\n    - Margin:               48\\r\\n    - Density:              76\\r\\n    - Severity:              0\\r\\n\", 'citation': None}}\n",
      "       name     role     type demographic description units missing_values\n",
      "0   BI-RADS  Feature  Integer        None        None  None            yes\n",
      "1       Age  Feature  Integer         Age        None  None            yes\n",
      "2     Shape  Feature  Integer        None        None  None            yes\n",
      "3    Margin  Feature  Integer        None        None  None            yes\n",
      "4   Density  Feature  Integer        None        None  None            yes\n",
      "5  Severity   Target   Binary        None        None  None             no\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "mammographic_mass = fetch_ucirepo(id=161) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = mammographic_mass.data.features \n",
    "y = mammographic_mass.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(mammographic_mass.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(mammographic_mass.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raisin\n",
    "\n",
    "7 features\n",
    "\n",
    "1 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 850, 'name': 'Raisin', 'repository_url': 'https://archive.ics.uci.edu/dataset/850/raisin', 'data_url': 'https://archive.ics.uci.edu/static/public/850/data.csv', 'abstract': 'Images of the Kecimen and Besni raisin varieties were obtained with CVS. A total of 900 raisins were used, including 450 from both varieties, and 7 morphological features were extracted.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 900, 'num_features': 7, 'feature_types': ['Real', 'Integer'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Fri Jan 05 2024', 'dataset_doi': '10.24432/C5660T', 'creators': ['İ̇lkay Çinar', 'Murat Koklu', 'Sakir Tasdemir'], 'intro_paper': {'ID': 261, 'type': 'NATIVE', 'title': 'Kuru Üzüm Tanelerinin Makine Görüşü ve Yapay Zeka Yöntemleri Kullanılarak Sınıflandırılması', 'authors': 'İ̇lkay Çinar, Murat Koklu, Sakir Tasdemir', 'venue': 'Gazi Journal of Engineering Sciences', 'year': 2020, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/6e67a463c29bde6a78ead7a10508674e693b74f3', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Images of Kecimen and Besni raisin varieties grown in Turkey were obtained with CVS. A total of 900 raisin grains were used, including 450 pieces from both varieties. These images were subjected to various stages of pre-processing and 7 morphological features were extracted. These features have been classified using three different artificial intelligence techniques.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1.) Area: Gives the number of pixels within the boundaries of the raisin.\\n2.) Perimeter: It measures the environment by calculating the distance between the boundaries of the raisin and the pixels around it.\\n3.) MajorAxisLength: Gives the length of the main axis, which is the longest line that can be drawn on the raisin.\\n4.) MinorAxisLength: Gives the length of the small axis, which is the shortest line that can be drawn on the raisin.\\n5.) Eccentricity: It gives a measure of the eccentricity of the ellipse, which has the same moments as raisins.\\n6.) ConvexArea: Gives the number of pixels of the smallest convex shell of the region formed by the raisin.\\n7.) Extent: Gives the ratio of the region formed by the raisin to the total pixels in the bounding box.\\n8.) Class: Kecimen and Besni raisin.', 'citation': 'CINAR I., KOKLU M. and TASDEMIR S., (2020), Classification of Raisin Grains Using Machine Vision and Artificial Intelligence Methods. Gazi Journal of Engineering Sciences, vol. 6, no. 3, pp. 200-209, December, 2020. '}}\n",
      "              name     role         type demographic  \\\n",
      "0             Area  Feature      Integer        None   \n",
      "1  MajorAxisLength  Feature   Continuous        None   \n",
      "2  MinorAxisLength  Feature   Continuous        None   \n",
      "3     Eccentricity  Feature   Continuous        None   \n",
      "4       ConvexArea  Feature      Integer        None   \n",
      "5           Extent  Feature   Continuous        None   \n",
      "6        Perimeter  Feature   Continuous        None   \n",
      "7            Class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0  Gives the number of pixels within the boundari...  None             no  \n",
      "1  It measures the environment by calculating the...  None             no  \n",
      "2  Gives the length of the main axis, which is th...  None             no  \n",
      "3  Gives the length of the small axis, which is t...  None             no  \n",
      "4  It gives a measure of the eccentricity of the ...  None             no  \n",
      "5  Gives the number of pixels of the smallest con...  None             no  \n",
      "6  Gives the ratio of the region formed by the ra...  None             no  \n",
      "7                          Kecimen and Besni raisin.  None             no  \n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "raisin = fetch_ucirepo(id=850) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = raisin.data.features \n",
    "y = raisin.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(raisin.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(raisin.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rice\n",
    "\n",
    "7 features\n",
    "\n",
    "1 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:     Area   Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity  \\\n",
      "0  15231  525.578979         229.749878          85.093788      0.928882   \n",
      "1  14656  494.311005         206.020065          91.730972      0.895405   \n",
      "2  14634  501.122009         214.106781          87.768288      0.912118   \n",
      "3  13176  458.342987         193.337387          87.448395      0.891861   \n",
      "4  14688  507.166992         211.743378          89.312454      0.906691   \n",
      "\n",
      "   Convex_Area    Extent   Class  \n",
      "0        15617  0.572896  Cammeo  \n",
      "1        15072  0.615436  Cammeo  \n",
      "2        14954  0.693259  Cammeo  \n",
      "3        13368  0.640669  Cammeo  \n",
      "4        15262  0.646024  Cammeo  \n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"Rice_Dataset_Commeo_and_Osmancik/Rice_Cammeo_Osmancik.xlsx\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"muratkokludataset/rice-dataset-commeo-and-osmancik\",\n",
    "  file_path,\n",
    "  # Specify the sheet name or index (optional)\n",
    "  pandas_kwargs={\"sheet_name\": 0},  # Load the first sheet\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes\n",
    "\n",
    "8 features\n",
    "\n",
    "1 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/uciml/pima-indians-diabetes-database?dataset_version_number=1&file_name=diabetes.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23.3k/23.3k [00:00<00:00, 357kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"diabetes.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"uciml/pima-indians-diabetes-database\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Segmentation\n",
    "\n",
    "3 features\n",
    "\n",
    "1 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 229, 'name': 'Skin Segmentation', 'repository_url': 'https://archive.ics.uci.edu/dataset/229/skin+segmentation', 'data_url': 'https://archive.ics.uci.edu/static/public/229/data.csv', 'abstract': 'The Skin Segmentation dataset is constructed over B, G, R color space. Skin and Nonskin dataset is generated using skin textures from face images of diversity of age, gender, and race people.', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Univariate'], 'num_instances': 245057, 'num_features': 3, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['y'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2009, 'last_updated': 'Tue Apr 09 2024', 'dataset_doi': '10.24432/C5T30C', 'creators': ['Rajen Bhatt', 'Abhinav Dhall'], 'intro_paper': None, 'additional_info': {'summary': 'The skin dataset is collected by randomly sampling B,G,R values from face images of various age groups (young, middle, and old), race groups (white, black, and asian), and genders obtained from FERET database and PAL database. Total learning sample size is 245057; out of which 50859 is the skin samples and 194198 is non-skin samples. Color FERET Image Database: http://face.nist.gov/colorferet/request.html, PAL Face Database from Productive Aging Laboratory, The University of Texas at Dallas: https://pal.utdallas.edu/facedb/. \\r\\n\\r\\n ', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'This dataset is of the dimension 245057 * 4 where first three columns are B,G,R (x1,x2, and x3 features) values and fourth column is of the class labels (decision variable y). ', 'citation': None}}\n",
      "  name     role     type demographic description units missing_values\n",
      "0    B  Feature  Integer        None        None  None             no\n",
      "1    G  Feature  Integer        None        None  None             no\n",
      "2    R  Feature  Integer        None        None  None             no\n",
      "3    y   Target   Binary        None        None  None             no\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "skin_segmentation = fetch_ucirepo(id=229) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = skin_segmentation.data.features \n",
    "y = skin_segmentation.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(skin_segmentation.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(skin_segmentation.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80/20 split\n",
    "# X and Y are the features and target variables, respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# From a pandas df\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
